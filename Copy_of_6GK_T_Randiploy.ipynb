{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 6GK_T_Randiploy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XsZVgUbf24piIo98KiM1JmbtUz2ee1c6",
      "authorship_tag": "ABX9TyMDoazYrparVM0+z4zVtxTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekbansal1977/ML/blob/main/Copy_of_6GK_T_Randiploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "1XhdnSz9_GjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "U7Uzz6LhErKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "mal-KuRfp1qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorboard_plugin_profile"
      ],
      "metadata": {
        "id": "jXfUmaRop7FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "metadata": {
        "id": "NFgkHpHuqDDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BhFtucLBECPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import datetime"
      ],
      "metadata": {
        "id": "OerPo7XwEsem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "metadata": {
        "id": "qhXY4qpKExZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQijXJBhBx_d"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ML/6GR.csv\", encoding = \"ISO-8859-1\")\n",
        "data.head()\n",
        "\n",
        "X = data.iloc[:,0:2].values.astype(int)\n",
        "y = data.iloc[:,2:3].values.astype(float)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10,random_state=1)\n",
        "\n",
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "#z_test = sc.transform(z_test)\n",
        "\n",
        "\n",
        "# Initialising the ANN\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "model.add(Dense(2,input_dim=2, activation = 'relu'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "model.add(Dense(units = 4, activation = 'relu'))\n",
        "\n",
        "# Adding the third hidden layer\n",
        "model.add(Dense(units = 4, activation = 'relu'))\n",
        "\n",
        "# Adding the FORTH hidden layer\n",
        "#model.add(Dense(units = 8, activation = 'relu'))\n",
        "\n",
        "# Adding the forth hidden layer\n",
        "model.add(Dense(units = 4, activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "\n",
        "#model.add(Dense(1))\n",
        "# Compiling the ANN\n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "#ann_viz(model, view=True, title=\"test\", filename=\"visualized\")\n",
        "#model.compile(optimizer = 'adam', loss = \"mae\", metrics=['accuracy'])\n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['accuracy'])\n",
        "\"\"\"\n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = 'accuracy')\n",
        "# Fitting the ANN to the Training set\n",
        "#model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae', 'mape'])\n",
        "\"\"\"\n",
        "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"log_dir/SGD\", histogram_freq=1)\n",
        "\n",
        "model.compile(optimizer=\"SGD\", loss=\"mse\", metrics=[\"mse\"])\n",
        "model.fit(X_train, y_train, batch_size = 50, validation_split=0.10,epochs = 100,  verbose=1, callbacks=[tensorboard_callback])\n",
        "\n",
        "#model.fit(X_train, y_train, batch_size = 20, validation_split=0.20,epochs = 1500,  verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score=model.evaluate(X_test,y_test,verbose=1)\n",
        "print(score)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "df1=pd.read_csv(\"/content/drive/MyDrive/ML/RainTestingData.csv\", encoding = \"ISO-8859-1\")\n",
        "z_test1=df1.iloc[:,0:2].values.astype(float)\n",
        "z_test1 = sc.transform(z_test1)\n",
        "z_pred1=model.predict(z_test1)\n",
        "print(\"Results for RR1\")\n",
        "print(z_pred1)\n",
        "\n",
        "#df1=pd.read_csv(\"/content/drive/MyDrive/ML/RainTestingData.csv\", encoding = \"ISO-8859-1\")\n",
        "z_test2=df1.iloc[:,4:6].values.astype(float)\n",
        "z_test2 = sc.transform(z_test2)\n",
        "z_pred2=model.predict(z_test2)\n",
        "print(\"Results for RR5\")\n",
        "print(z_pred2)\n",
        "\n",
        "#df3=pd.read_csv(\"/content/drive/MyDrive/ML/RainTestingData.csv\", encoding = \"ISO-8859-1\")\n",
        "z_test3=df1.iloc[:,8:10].values.astype(float)\n",
        "z_test3 = sc.transform(z_test3)\n",
        "z_pred3=model.predict(z_test3)\n",
        "print(\"Results for RR7\")\n",
        "print(z_pred3)\n",
        "\n",
        "#df4=pd.read_csv(\"/content/drive/MyDrive/ML/RainTestingData.csv\", encoding = \"ISO-8859-1\")\n",
        "z_test4=df1.iloc[:,12:14].values.astype(float)\n",
        "z_test4 = sc.transform(z_test4)\n",
        "z_pred4=model.predict(z_test4)\n",
        "print(\"Results for RR50\")\n",
        "print(z_pred4)\n",
        "\"\"\"\n",
        "df4=pd.read_csv(\"/content/drive/MyDrive/ML/H200GHz.csv\", encoding = \"ISO-8859-1\")\n",
        "z_test5=df1.iloc[:,16:18].values.astype(float)\n",
        "z_test5 = sc.transform(z_test5)\n",
        "z_pred5=model.predict(z_test5)\n",
        "print(\"Results for RR5\")\n",
        "print(z_pred5)\n",
        "\n",
        "df4=pd.read_csv(\"/content/drive/MyDrive/ML/H200GHz.csv\", encoding = \"ISO-8859-1\")\n",
        "z_test6=df1.iloc[:,20:22].values.astype(float)\n",
        "z_test6 = sc.transform(z_test6)\n",
        "z_pred6=model.predict(z_test6)\n",
        "print(\"Results for RR6\")\n",
        "print(z_pred6)\n",
        "#data1 = pd.read_csv(\"/content/drive/MyDrive/ML/Rain_10.csv\", encoding = \"ISO-8859-1\")\n",
        "#data1.head()\n",
        "\"\"\"\n",
        "from os import major\n",
        "#print(y_pred)\n",
        "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
        "df\n",
        "\n",
        "#from sklearn.metrics import accuracy_score \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('R2 Score ',r2_score(y_test,y_pred))\n",
        "\n",
        "print(len(X_test))\n",
        "print(len(y_test))\n",
        "\n",
        "plt.plot(X_test, y_test, color = 'red', label = 'Real dataTest')\n",
        "plt.plot(X_test, y_pred, color = 'blue', label = 'Predicted datatest')\n",
        "\n",
        "df = df.head(35)\n",
        "df.plot(kind='bar',figsize=(20,15))\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='red')\n",
        "plt.legend(fontsize=15)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "tm7XK2HX_NoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zButYA6T_Nc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pkl_Filename = \"model_tree.pkl\"  "
      ],
      "metadata": {
        "id": "-mWpWD-1-Rmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "svIlPhrl_CNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "BeSe3u9z-dkw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}