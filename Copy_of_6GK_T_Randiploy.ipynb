{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 6GK_T_Randiploy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XsZVgUbf24piIo98KiM1JmbtUz2ee1c6",
      "authorship_tag": "ABX9TyN2T3TgcERvHz5cFZ0BlHsb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekbansal1977/ML/blob/main/Copy_of_6GK_T_Randiploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "1XhdnSz9_GjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "U7Uzz6LhErKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "mal-KuRfp1qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorboard_plugin_profile"
      ],
      "metadata": {
        "id": "jXfUmaRop7FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "metadata": {
        "id": "NFgkHpHuqDDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BhFtucLBECPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import datetime"
      ],
      "metadata": {
        "id": "OerPo7XwEsem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "metadata": {
        "id": "qhXY4qpKExZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQijXJBhBx_d"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ML/6GR.csv\", encoding = \"ISO-8859-1\")\n",
        "data.head()\n",
        "\n",
        "X = data.iloc[:,0:2].values.astype(int)\n",
        "y = data.iloc[:,2:3].values.astype(float)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10,random_state=1)\n",
        "\n",
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "#z_test = sc.transform(z_test)\n",
        "\n",
        "\n",
        "# Initialising the ANN\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "model.add(Dense(2,input_dim=2, activation = 'relu'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "model.add(Dense(units = 4, activation = 'relu'))\n",
        "\n",
        "# Adding the third hidden layer\n",
        "model.add(Dense(units = 4, activation = 'relu'))\n",
        "\n",
        "# Adding the FORTH hidden layer\n",
        "#model.add(Dense(units = 8, activation = 'relu'))\n",
        "\n",
        "# Adding the forth hidden layer\n",
        "model.add(Dense(units = 4, activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "\n",
        "#model.add(Dense(1))\n",
        "# Compiling the ANN\n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "#ann_viz(model, view=True, title=\"test\", filename=\"visualized\")\n",
        "#model.compile(optimizer = 'adam', loss = \"mae\", metrics=['accuracy'])\n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['accuracy'])\n",
        "\"\"\"\n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = 'accuracy')\n",
        "# Fitting the ANN to the Training set\n",
        "#model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae', 'mape'])\n",
        "\"\"\"\n",
        "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"log_dir/SGD\", histogram_freq=1)\n",
        "\n",
        "model.compile(optimizer=\"SGD\", loss=\"mse\", metrics=[\"mse\"])\n",
        "model.fit(X_train, y_train, batch_size = 50, validation_split=0.10,epochs = 100,  verbose=1, callbacks=[tensorboard_callback])\n",
        "\n",
        "#model.fit(X_train, y_train, batch_size = 20, validation_split=0.20,epochs = 1500,  verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pkl_Filename = \"model_tree.pkl\"  "
      ],
      "metadata": {
        "id": "-mWpWD-1-Rmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "svIlPhrl_CNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "BeSe3u9z-dkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydantic"
      ],
      "metadata": {
        "id": "p4rh61wkTcUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Music(BaseModel):\n",
        "    accuracy_score: float \n",
        "    class Config:\n",
        "        schema_extra = {\n",
        "            \"example\": {\n",
        "                \"accuracy_score\": 0.838816, \n",
        "                \n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "dfgqyKDz_Wmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastapi"
      ],
      "metadata": {
        "id": "ItburbI4T2R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import pickle\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"model_tree.pkl\", \"rb\"))\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "    return {'message': 'This is the homepage of the API '}\n",
        "\n",
        "\n",
        "@app.post('/predict')\n",
        "def get_music_category(data: Music):\n",
        "    received = data.dict()\n",
        "    accuracy_score = received['accuracy_score']\n",
        "    pred_name = model.predict([[acousticness]]).tolist()[0]\n",
        "    return {'prediction': pred_name}"
      ],
      "metadata": {
        "id": "m6i3lLl__r0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ColabCode"
      ],
      "metadata": {
        "id": "MIAR2axjEIS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install favicon"
      ],
      "metadata": {
        "id": "9D_qF3l-XwmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "metadata": {
        "id": "Sxevh5YzRV2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "server.run_app(app=app)"
      ],
      "metadata": {
        "id": "M04NBw_3X2ER"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}